# VISION - Visual Intelligence for Surveillance, Identification and Organizational Networking

Version: 0.1

VISION is a tool aimed at providing dress code compliance analysis and face recognition capabilities.
This version (0.1) focuses on setting up the core face recognition backend, including database management for face embeddings and interaction with a separately running DeepFace API service. It also includes placeholders for YOLOv8-based dress analysis.

## Features (v0.1)

*   **Face Database Management:**
    *   Add new individuals with their face images to a PostgreSQL database.
    *   Store face embeddings generated by a DeepFace API.
    *   View registered individuals.
    *   Delete individuals or specific face images.
    *   Modify names of registered individuals.
*   **Face Recognition:**
    *   Capture a frame (simulated in this version, to be integrated with live video analysis).
    *   Detect faces in the captured frame using the DeepFace API.
    *   Recognize detected faces by comparing their embeddings against the database.
    *   Display the frame with detected faces labeled.
*   **Dress Analysis (Placeholder):**
    *   UI options to simulate uploading a video or entering a stream URL.
    *   Backend logic to process video with YOLOv8 (basic structure, OpenCV window for output).
    *   "Capture Frame" button to trigger face detection on the current video frame.

## Prerequisites

*   Python 3.8+
*   PostgreSQL server running and accessible.
*   Your custom DeepFace API service running (as per your `scripts/service.sh` on `http://127.0.0.1:5005`).
*   Your trained YOLOv8 model (`best.pt`) in the project's root directory.

## Setup

1.  **Clone the repository (if applicable) or create project directory.**

2.  **Create and activate a virtual environment:**
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows: venv\Scripts\activate
    ```

3.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Set up PostgreSQL:**
    *   Create a PostgreSQL database (e.g., `vision_db`).
    *   Create a database user with privileges for this database.

5.  **Configure Environment Variables:**
    *   Copy `.env.example` to `.env`:
        ```bash
        cp .env.example .env
        ```
    *   Edit `.env` with your actual database credentials and other settings:
        ```
        FLASK_APP=app.py
        FLASK_ENV=development
        DATABASE_URL=postgresql://username:password@host:port/database_name
        DEEPFACE_API_BASE_URL=http://127.0.0.1:5005
        YOLO_MODEL_PATH=best.pt
        UPLOAD_FOLDER=uploads/faces
        CAPTURED_FRAMES_FOLDER=captured_frames
        SECRET_KEY=your_strong_secret_key_here
        ```

6.  **Initialize the database:**
    *   The application will attempt to create the necessary tables on first run if they don't exist. (This will be handled in `database.py`).

7.  **Place your YOLOv8 model:**
    *   Ensure `best.pt` is in the root directory of the project (or update `YOLO_MODEL_PATH` in `.env`).

8.  **Ensure your DeepFace API service is running.**

## Running the Application

1.  **Activate the virtual environment (if not already):**
    ```bash
    source venv/bin/activate
    ```

2.  **Run the Flask application:**
    ```bash
    flask run
    ```
    The application will typically be available at `http://127.0.0.1:5000`.

## Project Structure

```
VISION_project/
├── app.py                   # Flask main application
├── database.py              # PostgreSQL interaction logic
├── deepface_client.py       # Client for DeepFace API service
├── yolo_analyzer.py         # YOLOv8 dress analysis
├── utils.py                 # Utility functions (e.g., embedding comparison)
├── best.pt                  # YOLOv8 model (ensure this is present)
├── requirements.txt         # Python dependencies
├── README.md
├── .env                     # Local environment variables (DO NOT COMMIT)
├── .env.example             # Example environment variables
├── static/                  # For CSS, JS
│   └── style.css
├── templates/               # HTML templates for Flask
│   ├── base.html
│   ├── index.html
│   ├── manage_faces.html
│   ├── add_person.html
│   ├── recognition_result.html
│   └── _flash_messages.html
├── uploads/                 # To store uploaded images for face DB
│   └── faces/
└── captured_frames/         # To store frames captured for face detection
```

## API Endpoints (DeepFace Service - Expected by this app)

This application expects your DeepFace API service (running at `DEEPFACE_API_BASE_URL`) to have the following endpoints:

*   **`POST /represent`**:
    *   Accepts `form-data` with `img` (file) and `model_name` (text, e.g., "Facenet").
    *   Response (example for one face):
        ```json
        {
          "embedding": [0.012, ..., -0.045]
          // or could be nested e.g. {"results": [{"embedding": [...]}]}
        }
        ```
*   **`POST /analyze`**:
    *   Accepts `form-data` with `img` (file) and `actions` (text, e.g., `[]` or `["age"]`).
    *   Response (example for multiple faces):
        ```json
        [
          {
            "region": {"x": 50, "y": 70, "w": 100, "h": 120},
            "age": 30, "gender": "Man", ... // other actions' results
          },
          {
            "region": {"x": 150, "y": 170, "w": 90, "h": 110},
            ...
          }
        ]
        ```
        The key part used is the `region` for bounding boxes.


## Notes
*   This is a work in progress. The dress analysis part is not fully implemented yet.
*   The face recognition part is designed to work with a separate DeepFace API service. Ensure it is running and accessible.
  
## Contributing
*   Contributions are welcome! Please fork the repository and submit a pull request.
*   For any issues or feature requests, please open an issue in the repository.
  
## Contributors
*   [Lalit Dumka](linkedin.com/in/lalitdumka) - Initial development and design.
*   [Karanpratap Singh Kharka ](linkedin) - .
*   [Kavi Kandpal](linkedin) - Data gathering and labelling.