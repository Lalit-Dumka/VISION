# VISION - Visual Intelligence for Surveillance, Identification and Organizational Networking

Version: 0.9

VISION is a comprehensive surveillance and monitoring system that provides advanced face recognition capabilities, movement tracking, and zone-based analytics. The system combines YOLOv8 object detection, DeepFace face recognition, and PostgreSQL database management to deliver a complete surveillance solution.

## Features

### **Face Recognition System**
*   **Face Database Management:**
    *   Add new individuals with their face images to PostgreSQL database
    *   Store face embeddings generated by DeepFace API
    *   View, edit, and manage registered individuals
    *   Delete individuals or specific face images
    *   Support for multiple face images per person
*   **Real-time Face Recognition:**
    *   Frame capture from video streams or files
    *   Face detection using configurable DeepFace backends (mtcnn, opencv, etc.)
    *   Face recognition with similarity scoring
    *   Annotated output with bounding boxes and confidence scores

### **Movement Monitoring & Surveillance**
*   **Camera Management:**
    *   Support for multiple IP cameras and video files
    *   RTSP stream support and local video file processing
    *   Camera configuration and zone definition interface
*   **Zone-based Tracking:**
    *   Interactive zone creation with polygon drawing
    *   Real-time person detection and tracking using YOLOv8
    *   Movement analytics between zones (entry, exit, transitions)
    *   Live person counts per zone
*   **Data Logging & Analytics:**
    *   PostgreSQL database logging of all movements and detections
    *   CSV export functionality for reporting
    *   Real-time dashboard with camera feeds and statistics
    *   Historical movement data and zone analytics

### **Video Processing**
*   **YOLOv8 Integration:**
    *   Person detection and tracking
    *   Real-time video stream processing
    *   Support for both trained models (best.pt) and default YOLOv8n
*   **Multi-threaded Processing:**
    *   Concurrent camera stream processing
    *   Live feed serving and snapshot generation
    *   Background processing with web interface control

## Prerequisites

*   Python 3.8+
*   PostgreSQL server running and accessible
*   DeepFace API service running on `http://127.0.0.1:8080` (see deepface/ folder)
*   YOLOv8 models (best.pt for custom training, yolov8n.pt included)
*   OpenCV and CUDA support (optional but recommended for performance)

## Setup

1.  **Clone the repository (if applicable) or create project directory.**

2.  **Create and activate a virtual environment:**
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows: venv\Scripts\activate
    ```

3.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Set up PostgreSQL:**
    *   Create a PostgreSQL database (e.g., `vision_db`).
    *   Create a database user with privileges for this database.

5.  **Configure Environment Variables:**
    *   Copy `.env.example` to `.env`:
        ```bash
        cp .env.example .env
        ```
    *   Edit `.env` with your actual database credentials and other settings:
        ```
        FLASK_APP=app.py
        FLASK_ENV=development
        DATABASE_URL=postgresql://username:password@host:port/database_name
        DEEPFACE_API_BASE_URL=http://127.0.0.1:8080
        YOLO_MODEL_PATH=best.pt
        UPLOAD_FOLDER=uploads/faces
        CAPTURED_FRAMES_FOLDER=captured_frames
        SECRET_KEY=your_strong_secret_key_here
        ```

6.  **Initialize the database:**
    *   The application will attempt to create the necessary tables on first run if they don't exist. (This will be handled in `database.py`).

7.  **Place your YOLOv8 model:**
    *   Ensure `best.pt` is in the root directory of the project (or update `YOLO_MODEL_PATH` in `.env`).

8.  **Ensure your DeepFace API service is running.**

## Running the Application

1.  **Activate the virtual environment (if not already):**
    ```bash
    source venv/bin/activate
    ```

2.  **Run the Flask application:**
    ```bash
    flask run
    ```
    The application will typically be available at `http://127.0.0.1:5000`.

## Project Structure

```
VISION/
├── app.py                          # Main Flask application
├── database.py                     # PostgreSQL database operations
├── deepface_client.py             # DeepFace API client
├── yolo_analyzer.py               # YOLOv8 video analysis (legacy)
├── utils.py                       # Utility functions and face matching
├── best.pt                        # Custom YOLOv8 model (place here)
├── yolov8n.pt                     # Default YOLOv8 nano model
├── requirements.txt               # Python dependencies
├── README.md
├── .env                          # Environment configuration
├── movement_monitoring/           # Movement monitoring module
│   ├── routes.py                 # Camera and zone management routes
│   └── static/                   # Module-specific assets
├── deepface/                     # DeepFace API service
│   ├── api/                      # API implementation
│   └── README.md                 # DeepFace service documentation
├── static/                       # Web assets (CSS, JS)
├── templates/                    # HTML templates
│   ├── base.html
│   ├── index.html
│   ├── manage_faces.html
│   ├── add_person.html
│   ├── recognition_result.html
│   ├── movement_monitoring_dashboard.html
│   ├── movement_monitoring_manage_cameras.html
│   ├── movement_monitoring_configure_zones.html
│   └── movement_monitoring_movements.html
├── uploads/faces/                # Stored face images
├── captured_frames/              # Captured frames and annotations
├── movement_monitoring_logs/     # CSV movement logs
└── extract_counts/               # Analytics and reporting data
```

## Usage

### **Web Interface**
1. **Home Dashboard** (`/`): Access all system features
2. **Face Management** (`/manage_faces`): Add/edit people and face images
3. **Movement Monitoring** (`/movement_monitoring/`): 
   - Camera dashboard with live feeds
   - Camera management and configuration
   - Zone definition and editing
   - Movement history and analytics

### **Camera Setup**
1. Navigate to Movement Monitoring → Manage Cameras
2. Add camera with name, type (stream/video_file), and source path
3. Configure zones by clicking points on camera snapshot
4. Start camera processing for real-time monitoring

### **Face Recognition**
1. Add people through Manage Faces interface
2. Upload clear face images for each person
3. Use "Capture Frame & Recognize" during video analysis
4. View results with annotated faces and confidence scores

## API Endpoints

### **Internal Flask Routes**
- `GET /` - Main dashboard
- `GET /manage_faces` - Face database management
- `POST /add_person` - Add new person with face image
- `POST /capture_frame_and_recognize` - Capture and recognize faces
- `GET /movement_monitoring/` - Surveillance dashboard
- `POST /movement_monitoring/camera/<id>/start` - Start camera processing
- `GET /movement_monitoring/camera/<id>/live_feed` - Live camera feed

### **DeepFace Service Endpoints** (Expected at `DEEPFACE_API_BASE_URL`)
- `POST /represent` - Generate face embeddings
- `POST /analyze` - Face detection and analysis
- `POST /verify` - Face verification between two images

## Database Schema

### **Core Tables**
- `people` - Person records
- `face_embeddings` - Face embedding vectors and metadata
- `se_cameras` - Camera configurations
- `se_camera_zones` - Zone definitions with polygon coordinates
- `se_detection_logs` - Detection events and counts
- `se_movement_logs` - Movement events between zones

## Configuration

### **Environment Variables**
```env
DATABASE_URL=postgresql://user:pass@localhost/vision_db
DEEPFACE_API_BASE_URL=http://127.0.0.1:8080
YOLO_MODEL_PATH=best.pt
DEEPFACE_DETECTOR_BACKEND=mtcnn
DEEPFACE_DETECTION_CONFIDENCE_THRESHOLD=0.90
UPLOAD_FOLDER=uploads/faces
CAPTURED_FRAMES_FOLDER=captured_frames
SECRET_KEY=your_secret_key
```

### **Performance Tuning**
- Adjust frame skip rates in camera processing
- Configure detection confidence thresholds
- Use CUDA-enabled PyTorch for faster inference
- Optimize PostgreSQL for high-frequency logging

## Recent Updates

*   ✅ Complete movement monitoring system with zone analytics
*   ✅ Multi-camera support with concurrent processing
*   ✅ Real-time web dashboard with live feeds
*   ✅ PostgreSQL integration for all data persistence
*   ✅ CSV export capabilities for reporting
*   ✅ Interactive zone configuration interface
*   ✅ Comprehensive face recognition with similarity scoring
*   ✅ YOLOv8 person tracking and movement analytics

## Notes

*   The system is not production-ready for surveillance applications
*   Face recognition requires the separate DeepFace API service to be running
*   Camera streams support RTSP, HTTP, and local video files
*   All movement data is logged to both database and CSV files
*   The web interface provides real-time monitoring capabilities

## Contributing
*   Contributions are welcome! Please fork the repository and submit a pull request.
*   For any issues or feature requests, please open an issue in the repository.
  
## Contributors
*   [Lalit Dumka](linkedin.com/in/lalitdumka) - Initial development and design.
*   [Karanpratap Singh Kharka ](linkedin) - .
*   [Kavi Kandpal](linkedin) - Data gathering and labelling.